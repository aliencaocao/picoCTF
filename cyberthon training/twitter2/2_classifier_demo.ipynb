{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2057192-d04d-4ecd-b178-751217548b82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cyberthon Data Science Training Materials\n",
    "# Author: Ragul Balaji <ragulbalaji@ctf.sg>\n",
    "# Dataset: Public Domain\n",
    "# ALT-TAB LABS LLP (C) 2019-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a6b16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you're opening this locally, make sure your environment has an install of the packages from the following versions. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8edf50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#! pip install pandas==1.1.5 scikit-learn==1.0.2 matplotlib==3.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84666b03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part I: The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1115e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can we predict who sent a tweet? ü§î\n",
    "\n",
    "This is a classification problem - the target variable belongs to either of the two categories, in our example, the categories are `Donald Trump` and `Justin Trudeau`.\n",
    "\n",
    "Let's dive in and explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278261e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We will load the file `train.csv` using pandas `read.csv()` into a `Dataframe` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcf4ea0-531e-4491-99d8-80c7700f010c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   trainid           author                                             status\n0        0   Justin Trudeau  RT @CQualtro: F√©licitations #Amazon pour l'exp...\n1        1   Justin Trudeau  Nous cherchons √† r√©soudre les enjeux qui compt...\n2        2  Donald J. Trump  Heading into the 12 days with great negotiatin...\n3        3  Donald J. Trump  The long anticipated release of the #JFKFiles ...\n4        4  Donald J. Trump  ....for the Middle Class. The House and Senate...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trainid</th>\n      <th>author</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Justin Trudeau</td>\n      <td>RT @CQualtro: F√©licitations #Amazon pour l'exp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Justin Trudeau</td>\n      <td>Nous cherchons √† r√©soudre les enjeux qui compt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Donald J. Trump</td>\n      <td>Heading into the 12 days with great negotiatin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Donald J. Trump</td>\n      <td>The long anticipated release of the #JFKFiles ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Donald J. Trump</td>\n      <td>....for the Middle Class. The House and Senate...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66dd41c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Target variable and Predictor(s)\n",
    "\n",
    "We first identify that our target variable is `\"author\"`, and our predictor variable is `\"status\"`.\n",
    "\n",
    "You can also apply stemming/lemmatization (covered earlier), or engineer new features that could be useful in model prediction (not covered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9020070d-f9ca-499c-9e0c-d449af671d68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# identify target and predictor\n",
    "y = data['author']\n",
    "X = data['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5e137",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training set and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a57cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training set\n",
    "\n",
    "- data used to train our model\n",
    "- data and labels are provided to the model, the model tune its parameters to fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9ccd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Validation set\n",
    "\n",
    "- Data used to test our model after it has been trained\n",
    "- Predicted labels are compared against our true labels to compute the accuracy, to determine the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083e0ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why shouldn't the model be trained using the test set too?\n",
    "\n",
    "- We want our model to generalize well on unseen data.\n",
    "- Trained model gains information about the validation set and the predictions made by the model will be biased towards the validation set, resulting in overestimation of the model's performance.\n",
    "\n",
    "Here, we specify some parameters\n",
    "- `random_state=42` : for reproducible results\n",
    "- `test_size=0.25` : dataset will be split into 75% training and 25% validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e48536",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great! Now that we have split our data, are we able to train the model using training set yet? No!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8dac6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Text Vectorization\n",
    "\n",
    "As covered earlier, machine learning models require numerical numbers as inputs. Text data unfortunately doesn't work here.üòû\n",
    "\n",
    "Let's use `CountVectorizer` to convert the tweets into numerical vectors!\n",
    "\n",
    "We first create an instance of `CountVectorizer`.\n",
    "\n",
    "We want the model to learn the vocabulary from the training set, so we fit the `CountVectorizer` using only the training set, not the validation set.\n",
    "\n",
    "Then transform the training set and validation set to encode each tweet as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5970924-74e9-4a7e-b93b-757f1b17d909",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "import re\n",
    "\n",
    "def clean(x):\n",
    "    # x = re.sub(r'https://t.co/\\S{0,10}', '', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer(preprocessor=clean)\n",
    "\n",
    "# Fit and transform/vectorize the training set\n",
    "vec_x = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate the document term matrix. \n",
    "\n",
    "There are 2 documents and 10 unique terms, hence 2x10 matrix.\n",
    "\n",
    "Cell specify the count of term in the document."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning Model\n",
    "\n",
    "We will use the library `sklearn` due to its wide selection of models. Machine learning models in `sklearn` are objects which need to be initialized first.\n",
    "\n",
    "Let's use what we learnt earlier - Decision üå≤!\n",
    "\n",
    "Here, we specify some parameters\n",
    "- `random_state=42` : for reproducible results\n",
    "- `max_depth=8` : to limit tree depth to 8\n",
    "\n",
    "For detailed documention, refer here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Some useful methods\n",
    "- `.fit()` : to pass in our training set to train a machine learning model\n",
    "- `.predict()` : to pass in our validation set to make predictions using our model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "\n",
    "# Initialize our machine learning model\n",
    "model = ensemble.ExtraTreesClassifier(n_estimators=3000, verbose=1, n_jobs=-1)\n",
    "model2 = ensemble.RandomForestClassifier(n_estimators=3000, verbose=1, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "ExtraTreesClassifier(n_estimators=3000, n_jobs=-1, verbose=1)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(vec_x.toarray(),y)\n",
    "# model2.fit(vec_x.toarray(),y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 3000 out of 3000 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "df_test = pd.read_csv('test.csv')\n",
    "X_test = df_test['status']\n",
    "vec_x_test = vectorizer.transform(X_test)\n",
    "preds = model.predict(vec_x_test.toarray())\n",
    "\n",
    "df_ans = pd.read_csv('submission.csv')\n",
    "df_ans['author'] = preds\n",
    "df_ans.to_csv('submission_ans.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGraderClient: Successfully Connected!\n",
      "[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm TWEET_CLASSIFY @dca2c8397283\n",
      "ProofOfWork Challenge =>  ('CTFSGRB7008cbad939aca5f41b7fe09932484cd', 22)\n",
      "ProofOfWork Answer Found! =>  3718578\n"
     ]
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"WhoTweetThis (challenge)\"},\"id\":\"cl22q7i9zcskh08272nx5klbx\",\"status\":\"PARTIALLY_CORRECT\",\"multiplier\":0.6815,\"submittedBy\":{\"username\":\"hci-69\"},\"createdAt\":\"2022-04-17T03:26:03Z\"}'"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, 'C:/Users/alien/Documents/PyCharm Projects/Cyberthon 2021/pyctfsglib.py')\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "\n",
    "USER_TOKEN = \"WrlLCkymxwtgFwRHZsdmKfSwcdqIpnqoXEtRkciVRZJfBJUgcEJoxVZjNTQRdqkR\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50501/\",\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50502/\"\n",
    "])\n",
    "\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)\n",
    "grader.submitFile('submission_ans.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II: Model Interpretability"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How does the model make its predictions? Let's visualize the üå≤!\n",
    "\n",
    "### Example: Model predicts Justin Trudeau sent the tweet\n",
    "Starting at the root node (the node where the üå≤ begins), <br>\n",
    "if `de` is absent in the tweet, go to the left branch, <br>\n",
    "if `rt` is present in the tweet, go to the right branch, <br>\n",
    "if `thank` and `hannity` and `seanhannity` are absent in the tweet, <br>\n",
    "the model predicts the tweet sender as `Justin Trudeau`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RUN THIS PART AFTER YOU ARE \n",
    "# DONE WITH PART 1\n",
    "\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "tree.plot_tree(model, fontsize=10, filled=True, class_names=['Donald', 'Justin'], feature_names=vectorizer.get_feature_names())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The _absence_ of `de`, _presence_ of `rt`, _absence_ of `thank` and `hannity` and `seanhannity` result in the model predicting `Justin Trudeau` as the tweet sender."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part III: Model Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, you are able to identify what features the model uses to make its predictions. \n",
    "\n",
    "Are you able to make minimal modifications to a tweet to fool the model?\n",
    "\n",
    "We have established in Part II that `de`, `rt`, `thank`, `hannity` and `seanhannity` are features used by the model to make its predictions.\n",
    "\n",
    "Specifically, the absence of `de`, presence of `rt`, absence of `thank` and `hannity` and `seanhannity` result in the model predicting `Justin Trudeau` as the tweet sender.\n",
    "\n",
    "Using the same features, what would fool the model to classify `Donald Trump` as the tweet sender? If `thank` or `hannity` is present in the tweet!\n",
    "\n",
    "Let's explore modifying a sample tweet from the validation set!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampleid = 1\n",
    "truth = y_validation.iloc[sampleid]\n",
    "\n",
    "print('tweet:', repr(X_validation.iloc[sampleid]))\n",
    "print('\\n   classifies as:', y_pred[sampleid])\n",
    "print(' ground truth is:', truth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we want to modify an input so that the model misclassifies\n",
    "\n",
    "original = X_validation.iloc[sampleid]\n",
    "attack1 = X_validation.iloc[sampleid] + ' thank'\n",
    "attack2 = X_validation.iloc[sampleid] + ' hannity'\n",
    "attack3 = X_validation.iloc[sampleid] + ' seanhannity'\n",
    "\n",
    "print('\\n original:', repr(original))\n",
    "print('\\n attack1:', repr(attack1))\n",
    "print('\\n attack2:', repr(attack2))\n",
    "print('\\n attack3:', repr(attack3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, same concept as before - vectorize text before input to machine learning models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vectorize the attacks\n",
    "vec_attack = vectorizer.transform([original, attack1, attack2, attack3])\n",
    "\n",
    "# feed attacks into model for prediction\n",
    "attack_pred = model.predict(vec_attack)\n",
    "\n",
    "print('\\n   truth:', truth)\n",
    "print('\\n   original:', attack_pred[0])\n",
    "print('\\n   attack1:', attack_pred[1])\n",
    "print('\\n   attack2:', attack_pred[2])\n",
    "print('\\n   attack3:', attack_pred[3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6900ef16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modifying the sample tweet by adding `thank` or `hannity` fooled the model to predict `Donald Trump` instead of `Justin Trudeau` as the tweet sender.\n",
    "\n",
    "Can you identify another modification to fool the model? üòÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174c7ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}