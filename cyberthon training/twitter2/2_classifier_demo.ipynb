{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcf4ea0-531e-4491-99d8-80c7700f010c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data2 = pd.read_csv('train1.csv')\n",
    "data = pd.concat([data, data2])\n",
    "# identify target and predictor\n",
    "y = data['author']\n",
    "X = data['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8dac6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Text Vectorization\n",
    "\n",
    "As covered earlier, machine learning models require numerical numbers as inputs. Text data unfortunately doesn't work here.ðŸ˜ž\n",
    "\n",
    "Let's use `CountVectorizer` to convert the tweets into numerical vectors!\n",
    "\n",
    "We first create an instance of `CountVectorizer`.\n",
    "\n",
    "We want the model to learn the vocabulary from the training set, so we fit the `CountVectorizer` using only the training set, not the validation set.\n",
    "\n",
    "Then transform the training set and validation set to encode each tweet as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5970924-74e9-4a7e-b93b-757f1b17d909",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer().fit(X)\n",
    "# Fit and transform/vectorize the training set\n",
    "vec_x = vectorizer.transform(X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True).fit(vec_x)\n",
    "vec_x = tfidf_transformer.transform(vec_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate the document term matrix. \n",
    "\n",
    "There are 2 documents and 10 unique terms, hence 2x10 matrix.\n",
    "\n",
    "Cell specify the count of term in the document."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning Model\n",
    "\n",
    "We will use the library `sklearn` due to its wide selection of models. Machine learning models in `sklearn` are objects which need to be initialized first.\n",
    "\n",
    "Let's use what we learnt earlier - Decision ðŸŒ²!\n",
    "\n",
    "Here, we specify some parameters\n",
    "- `random_state=42` : for reproducible results\n",
    "- `max_depth=8` : to limit tree depth to 8\n",
    "\n",
    "For detailed documention, refer here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Some useful methods\n",
    "- `.fit()` : to pass in our training set to train a machine learning model\n",
    "- `.predict()` : to pass in our validation set to make predictions using our model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "\n",
    "# Initialize our machine learning model\n",
    "model = linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=1000, tol=None, n_jobs=-1)  # reached 97 once but cant reproduce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "SGDClassifier(alpha=0.001, n_jobs=-1, tol=None)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(vec_x.toarray(),y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Make predictions on test set\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_test \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m X_test \u001B[38;5;241m=\u001B[39m df_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m vec_x_test \u001B[38;5;241m=\u001B[39m vectorizer\u001B[38;5;241m.\u001B[39mtransform(X_test)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "df_test = pd.read_csv('test.csv')\n",
    "X_test = df_test['status']\n",
    "vec_x_test = vectorizer.transform(X_test)\n",
    "vec_x_test = tfidf_transformer.transform(vec_x_test)\n",
    "preds = model.predict(vec_x_test.toarray())\n",
    "\n",
    "df_ans = pd.read_csv('submission.csv')\n",
    "df_ans['author'] = preds\n",
    "df_ans.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGraderClient: Successfully Connected!\n",
      "[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm TWEET_CLASSIFY @88cf113df561\n",
      "ProofOfWork Challenge =>  ('CTFSGRB25c21a49e87c28c32126717d49123f8f', 22)\n",
      "ProofOfWork Answer Found! =>  4281005\n"
     ]
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"WhoTweetThis (challenge)\"},\"id\":\"cl25v4gtwe88p0832xg3xjpqj\",\"status\":\"CORRECT\",\"multiplier\":1,\"submittedBy\":{\"username\":\"hci-69\"},\"createdAt\":\"2022-04-19T08:06:58Z\"}'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, 'C:/Users/alien/Documents/PyCharm Projects/Cyberthon 2021/pyctfsglib.py')\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "USER_TOKEN = \"WrlLCkymxwtgFwRHZsdmKfSwcdqIpnqoXEtRkciVRZJfBJUgcEJoxVZjNTQRdqkR\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50501/\",\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50502/\"\n",
    "])\n",
    "\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)\n",
    "grader.submitFile('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}