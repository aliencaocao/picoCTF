{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "Found 3081 files belonging to 34 classes.\n",
      "Using 2465 files for training.\n",
      "\n",
      "Validation data:\n",
      "Found 3081 files belonging to 34 classes.\n",
      "Using 616 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# data loading config\n",
    "batch_size = 64\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "labels = 'inferred'\n",
    "label_mode = 'categorical'  # sparse one hot encoding\n",
    "color_mode = 'rgb'\n",
    "shuffle = True\n",
    "seed = 69\n",
    "val_split = 0.2\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print('Training data:')\n",
    "train = tf.keras.utils.image_dataset_from_directory('train', labels=labels, label_mode=label_mode,\n",
    "color_mode=color_mode, shuffle=shuffle, seed=seed, image_size=(img_height, img_width), batch_size=batch_size, validation_split=val_split, subset='training')\n",
    "train_class_names = train.class_names\n",
    "\n",
    "print('\\nValidation data:')\n",
    "val = tf.keras.utils.image_dataset_from_directory('train', labels=labels, label_mode=label_mode,\n",
    "color_mode=color_mode, shuffle=shuffle, seed=seed, image_size=(img_height, img_width), batch_size=batch_size, validation_split=val_split, subset='validation')\n",
    "val_class_names = val.class_names\n",
    "\n",
    "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-m (Functiona  (None, 4, 4, 1280)       53150388  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               5243136   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 34)                8738      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,468,054\n",
      "Trainable params: 58,176,022\n",
      "Non-trainable params: 292,032\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 100s 601ms/step - loss: 2.4649 - accuracy: 0.4300 - val_loss: 1.8959 - val_accuracy: 0.6218 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 77s 2s/step - loss: 1.4516 - accuracy: 0.7874 - val_loss: 1.2231 - val_accuracy: 0.8458 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 1.1249 - accuracy: 0.8937 - val_loss: 1.0626 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.9771 - accuracy: 0.9448 - val_loss: 0.9791 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.9405 - accuracy: 0.9493 - val_loss: 0.9274 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.8697 - accuracy: 0.9736 - val_loss: 0.9114 - val_accuracy: 0.9383 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.8285 - accuracy: 0.9813 - val_loss: 0.8488 - val_accuracy: 0.9448 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.7766 - accuracy: 0.9923 - val_loss: 0.8283 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.7694 - accuracy: 0.9890 - val_loss: 0.8624 - val_accuracy: 0.9383 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.7497 - accuracy: 0.9955 - val_loss: 0.8235 - val_accuracy: 0.9513 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.7356 - accuracy: 0.9968 - val_loss: 0.8222 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 10s 250ms/step - loss: 0.7270 - accuracy: 0.9968 - val_loss: 0.8285 - val_accuracy: 0.9497 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7305 - accuracy: 0.9947\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.7305 - accuracy: 0.9947 - val_loss: 0.8794 - val_accuracy: 0.9399 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 10s 251ms/step - loss: 0.7270 - accuracy: 0.9939 - val_loss: 0.7721 - val_accuracy: 0.9708 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 10s 247ms/step - loss: 0.7073 - accuracy: 0.9992 - val_loss: 0.7655 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 9s 243ms/step - loss: 0.7039 - accuracy: 0.9996 - val_loss: 0.7637 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 10s 249ms/step - loss: 0.7029 - accuracy: 0.9996 - val_loss: 0.7639 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 10s 253ms/step - loss: 0.6998 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 10s 246ms/step - loss: 0.6993 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6974 - accuracy: 1.0000\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "39/39 [==============================] - 10s 248ms/step - loss: 0.6974 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.6988 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.9740 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 10s 245ms/step - loss: 0.7003 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.9740 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 10s 252ms/step - loss: 0.6994 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.9740 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x14ae89d05e0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model layers\n",
    "xIn = Input((img_height, img_width, 3))\n",
    "# x = tf.keras.layers.RandomFlip()(xIn)\n",
    "effnet = tf.keras.applications.efficientnet_v2.EfficientNetV2M(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3),)\n",
    "x = effnet(xIn)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='swish')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='swish')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "xOut = Dense(len(train_class_names), dtype=tf.float32)(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=xIn, outputs=xOut)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "model.summary()\n",
    "model.fit(train, epochs=100, batch_size=64, validation_data=val, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: comnist_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('comnist_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = load_model('comnist')\n",
    "model2 = load_model('comnist_aug')\n",
    "model3 = load_model('comnist_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12399 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory('test', labels=None, label_mode=None,\n",
    "color_mode=color_mode, shuffle=False, seed=seed, image_size=(img_height, img_width), batch_size=batch_size)\n",
    "filenames = test.file_paths\n",
    "filenames = [file.split('\\\\')[-1].split('.jpg')[0] for file in filenames]\n",
    "test = test.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "preds = model.predict(test)\n",
    "preds = tf.nn.softmax(preds)\n",
    "preds2 = model2.predict(test)\n",
    "preds2 = tf.nn.softmax(preds2)\n",
    "preds3 = model3.predict(test)\n",
    "preds3 = tf.nn.softmax(preds3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "preds_comb = preds * 0.45 +  preds2 * 0.2 + preds3 * 0.35\n",
    "preds_comb = tf.argmax(preds_comb, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "preds_dict = dict()\n",
    "for i in range(len(preds)):\n",
    "    preds_dict.update({filenames[i]: train_class_names[int(preds_comb[i])]})\n",
    "\n",
    "import pandas as pd\n",
    "pred_df = pd.read_csv('test.csv')\n",
    "pred_df_unordered = pd.DataFrame.from_dict(preds_dict, columns=['label'], orient='index')\n",
    "pred_df_unordered.reset_index(inplace=True)\n",
    "pred_df_unordered.columns = ['id', 'label']\n",
    "\n",
    "pred_df_aligned = pred_df.merge(pred_df_unordered, on='id', how='left')\n",
    "pred_df_aligned.drop(['label_x'], axis=1, inplace=True)\n",
    "pred_df_aligned.columns = ['id', 'label']\n",
    "pred_df_aligned.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGraderClient: Successfully Connected!\n",
      "[SERVER] MOTD: CHECK your USER_TOKEN and GRADER_URL HTTP address! I'm CoMNIST @4d907f5f7099\n",
      "ProofOfWork Challenge =>  ('CTFSGRB7cb006d1a30196962961c580062c965f', 22)\n",
      "ProofOfWork Answer Found! =>  711677\n"
     ]
    },
    {
     "data": {
      "text/plain": "'{\"challenge\":{\"name\":\"CoMNIST\"},\"id\":\"cl231m5qbcxiz07639i26r9jb\",\"status\":\"PARTIALLY_CORRECT\",\"multiplier\":0.9731,\"submittedBy\":{\"username\":\"hci-69\"},\"createdAt\":\"2022-04-17T08:45:22Z\"}'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to graders\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, 'C:/Users/alien/Documents/PyCharm Projects/Cyberthon 2021/pyctfsglib.py')\n",
    "import pyctfsglib as ctfsg\n",
    "import random\n",
    "\n",
    "USER_TOKEN = \"WrlLCkymxwtgFwRHZsdmKfSwcdqIpnqoXEtRkciVRZJfBJUgcEJoxVZjNTQRdqkR\" # You need to fill this up\n",
    "GRADER_URL = random.choice([\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50201/\",\n",
    "  \"http://chals.cyberthon22t.ctf.sg:50202/\"\n",
    "])\n",
    "\n",
    "grader = ctfsg.DSGraderClient(GRADER_URL, USER_TOKEN)\n",
    "grader.submitFile('submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}